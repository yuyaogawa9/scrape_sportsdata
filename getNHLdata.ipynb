{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lxml import html\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nhl_games(year):\n",
    "    \"\"\"\n",
    "    Scrape NHL game results for a given year from Hockey Reference.\n",
    "\n",
    "    Args:\n",
    "        year (int): The year of the games.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the scraped game results.\n",
    "    \"\"\"\n",
    "    # Format the URL for the given year\n",
    "    url = f\"https://www.hockey-reference.com/leagues/NHL_{year}_games.html\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Connection\": \"keep-alive\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Fetch the webpage content\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        tree = html.fromstring(response.content)\n",
    "\n",
    "        # XPath expression to select rows in the table body\n",
    "        rows = tree.xpath('//table[@id=\"games\"]/tbody/tr')\n",
    "\n",
    "        # Initialize a list to store game data\n",
    "        games = []\n",
    "\n",
    "        # Iterate over each row and extract data\n",
    "        for row in rows:\n",
    "            date = row.xpath('./th[@data-stat=\"date_game\"]/a/text()')\n",
    "            visitor_team = row.xpath('./td[@data-stat=\"visitor_team_name\"]/a/text()')\n",
    "            visitor_goals = row.xpath('./td[@data-stat=\"visitor_goals\"]/text()')\n",
    "            home_team = row.xpath('./td[@data-stat=\"home_team_name\"]/a/text()')\n",
    "            home_goals = row.xpath('./td[@data-stat=\"home_goals\"]/text()')\n",
    "            attendance = row.xpath('./td[@data-stat=\"attendance\"]/text()')\n",
    "            game_length = row.xpath('./td[@data-stat=\"game_duration\"]/text()')\n",
    "            arena = row.xpath('./td[@data-stat=\"arena_name\"]/a/text()')\n",
    "\n",
    "            # Append a dictionary to the games list\n",
    "            games.append({\n",
    "                'date': date[0] if date else None,\n",
    "                'visitor_team': visitor_team[0] if visitor_team else None,\n",
    "                'visitor_goals': visitor_goals[0] if visitor_goals else None,\n",
    "                'home_team': home_team[0] if home_team else None,\n",
    "                'home_goals': home_goals[0] if home_goals else None,\n",
    "                'attendance': attendance[0].replace(\",\", \"\") if attendance else None,\n",
    "                'game_length': game_length[0] if game_length else None,\n",
    "                'arena': arena[0] if arena else None\n",
    "            })\n",
    "\n",
    "        # Convert the games list to a pandas DataFrame\n",
    "        return pd.DataFrame(games)\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching the webpage: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nhl_games_all_years():\n",
    "    \"\"\"\n",
    "    Scrape NHL game results from January 2000 to the most recent results.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the combined game results for all years.\n",
    "    \"\"\"\n",
    "    # Start and end year\n",
    "    start_year = 2000\n",
    "    end_year = pd.Timestamp.now().year\n",
    "    \n",
    "    all_games = []\n",
    "\n",
    "    # Iterate over years\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        print(f\"Scraping {year}...\")\n",
    "        df = scrape_nhl_games(year)\n",
    "        if not df.empty:\n",
    "            all_games.append(df)\n",
    "        time.sleep(3)  # Wait for 3 seconds between requests\n",
    "\n",
    "    # Combine all dataframes into one\n",
    "    return pd.concat(all_games, ignore_index=True)\n",
    "\n",
    "# Example usage\n",
    "df_all_nhl = scrape_nhl_games_all_years()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_nhl.to_csv('NHL.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
